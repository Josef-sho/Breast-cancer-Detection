# -*- coding: utf-8 -*-
"""final detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CCCW4zWHxTwEwu1HmSQaQ2LePgsMpD8e
"""



import tensorflow as tf
import numpy as np
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, AveragePooling2D
from tensorflow.keras.applications.inception_v3 import InceptionV3
# from mrcnn.config import Config
# from mrcnn import model as modellib, utils
import cv2

# Load pre-trained weights for Mask R-CNN
# model_path = 'https://github.com/matterport/Mask_RCNN/releases/download/v1.0/mask_rcnn_coco.h5'
# config = Config()
# model1 = modellib.MaskRCNN(mode='inference', config=config, model_dir='logs/')
# model1.load_weights(model_path, by_name=True)

#Mount Google Drive
 from google.colab import drive
 drive.mount('/content/drive')

batch_size = 32
# from google.colab import files

# Load the test data from the .npy file
test_data = np.load('/content/drive/MyDrive/dataset/test10_data/test10_data.npy')

# Create a tf.data.Dataset object from the loaded test data
test_dataset = tf.data.Dataset.from_tensor_slices(test_data)
test_dataset = test_dataset.batch(batch_size)
test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)

# Define the input data pipeline functions
def parse_tfrecord(example_proto):
    features = {
        'label': tf.io.FixedLenFeature([], tf.int64),
        'label_normal': tf.io.FixedLenFeature([], tf.int64),
        'image': tf.io.FixedLenFeature([], tf.string),
    }
    parsed_features = tf.io.parse_single_example(example_proto, features)
    label = parsed_features['label_normal']
    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)
    image = tf.reshape(image, [299, 299, 1])
    return image, label




def load_dataset(file_patterns, batch_size):
    dataset = tf.data.Dataset.from_tensor_slices(file_patterns)
    dataset = dataset.interleave(
        lambda file_pattern: tf.data.TFRecordDataset(file_pattern).map(parse_tfrecord),
        cycle_length=len(file_patterns),
        num_parallel_calls=tf.data.AUTOTUNE
    )
    dataset = dataset.shuffle(buffer_size=10000)
    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)
    return dataset

# Load the training dataset
train_folders = ['/content/drive/MyDrive/dataset/training10_0/training10_0.tfrecords', '/content/drive/MyDrive/dataset/training10_1/training10_1.tfrecords']
train_dataset = load_dataset(train_folders, batch_size=32)

# Define the AlexNet-like model architecture
def alexnet():
    model = tf.keras.Sequential()
    model.add(Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=(299, 299, 1)))
    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))
    model.add(Conv2D(256, (5, 5), strides=(1, 1), padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))
    model.add(Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu'))
    model.add(Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu'))
    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))
    model.add(Flatten())
    model.add(Dense(4096, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(4096, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1, activation='sigmoid'))
    return model

# Create an instance of the AlexNet-like model
model = alexnet()

# Compile the modelv
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Convert the train_dataset to NumPy arrays
train_images = []
train_labels = []
for image, label in train_dataset:
    train_images.append(image)
    train_labels.append(label)
train_images = tf.concat(train_images, axis=0)
train_labels = tf.concat(train_labels, axis=0)
train_images = train_images.numpy()
train_labels = train_labels.numpy()

# Train the model
model.fit(train_images, train_labels, epochs=50, validation_data=test_dataset)

# Define the InceptionV3 model architecture
def inception_v3():
    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))
    x = base_model.output
    x = AveragePooling2D(pool_size=(7, 7))(x)
    x = Flatten()(x)
    predictions = Dense(1, activation='sigmoid')(x)
    model2 = tf.keras.Model(inputs=base_model.input, outputs=predictions)
    return model2

# Create an instance of the InceptionV3 model
model2 = inception_v3()

# Compile the model
model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Assuming your grayscale images are stored in the variable 'train_images'
# Convert grayscale images to RGB
train_images_rgb = np.repeat(train_images, 3, axis=-1)

# Now 'train_images_rgb' will have the shape (num_samples, 299, 299, 3) with RGB channels

# Train the model
model2.fit(train_images, train_labels, epochs=50, validation_data=test_dataset)

# Define the Mask R-CNN configuration class
class MaskRCNNConfig(Config):
    # Set configuration parameters
    NAME = "mask_rcnn_coco"
    IMAGES_PER_GPU = 1
    NUM_CLASSES = 1 + 80  # COCO has 80 classes

config = MaskRCNNConfig()

# Instantiate the Mask R-CNN model
model3 = modellib.MaskRCNN(mode='training', config=config, model_dir='logs/')

# Load the training labels
train_labels = np.load('/content/drive/MyDrive/cv10_labels.npy')

# Compile the model
model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model3.fit(train_images, train_labels, epochs=10, validation_data=test_dataset)

# Make predictions on new images
image = cv2.imread('/content/drive/MyDrive/path/to/image')
results = model1.detect([image], verbose=1)